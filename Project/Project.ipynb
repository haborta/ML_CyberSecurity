{"cells":[{"cell_type":"code","source":["!pip3 install tensorflow_text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wL4BTi57Bq_G","executionInfo":{"status":"ok","timestamp":1670870393290,"user_tz":300,"elapsed":96237,"user":{"displayName":"Shiyang Zheng","userId":"10224114907197839961"}},"outputId":"75dfc09d-ac72-46e2-dd85-7577233a5788"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow_text\n","  Downloading tensorflow_text-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n","\u001b[K     |████████████████████████████████| 5.8 MB 4.8 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_text) (0.12.0)\n","Collecting tensorflow<2.12,>=2.11.0\n","  Downloading tensorflow-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n","\u001b[K     |████████████████████████████████| 588.3 MB 16 kB/s \n","\u001b[?25hCollecting tensorflow-estimator<2.12,>=2.11.0\n","  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n","\u001b[K     |████████████████████████████████| 439 kB 57.1 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.15.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (0.2.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.14.1)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.3.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.6.3)\n","Collecting flatbuffers>=2.0\n","  Downloading flatbuffers-22.12.6-py2.py3-none-any.whl (26 kB)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (0.4.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (3.1.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (2.1.1)\n","Collecting tensorboard<2.12,>=2.11\n","  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n","\u001b[K     |████████████████████████████████| 6.0 MB 45.2 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (57.4.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.51.1)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (4.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (21.3)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (0.28.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (14.0.6)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.21.6)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (3.19.6)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (3.3.0)\n","Collecting keras<2.12,>=2.11.0\n","  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 48.1 MB/s \n","\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.38.4)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.8.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.4.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2.23.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2.15.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.6.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.4.6)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (4.9)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (5.2.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (4.13.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.11.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.4.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2022.9.24)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.2.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.0.9)\n","Installing collected packages: tensorflow-estimator, tensorboard, keras, flatbuffers, tensorflow, tensorflow-text\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.9.0\n","    Uninstalling tensorflow-estimator-2.9.0:\n","      Successfully uninstalled tensorflow-estimator-2.9.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.9.1\n","    Uninstalling tensorboard-2.9.1:\n","      Successfully uninstalled tensorboard-2.9.1\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.9.0\n","    Uninstalling keras-2.9.0:\n","      Successfully uninstalled keras-2.9.0\n","  Attempting uninstall: flatbuffers\n","    Found existing installation: flatbuffers 1.12\n","    Uninstalling flatbuffers-1.12:\n","      Successfully uninstalled flatbuffers-1.12\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.9.2\n","    Uninstalling tensorflow-2.9.2:\n","      Successfully uninstalled tensorflow-2.9.2\n","Successfully installed flatbuffers-22.12.6 keras-2.11.0 tensorboard-2.11.0 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-text-2.11.0\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"U6W6TlB3ASOx","executionInfo":{"status":"ok","timestamp":1670870503955,"user_tz":300,"elapsed":4100,"user":{"displayName":"Shiyang Zheng","userId":"10224114907197839961"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import warnings\n","import tensorflow_hub as hub\n","warnings.filterwarnings('ignore')\n"]},{"cell_type":"code","source":["from google.colab import drive, files\n","drive.mount('/content/drive')\n","!cp /content/drive/MyDrive/MLCYBER/Project/load_dataset.py .\n","!cp /content/drive/MyDrive/MLCYBER/Project/load_model.py ."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q_2fNFIpAdQl","executionInfo":{"status":"ok","timestamp":1670870529963,"user_tz":300,"elapsed":22735,"user":{"displayName":"Shiyang Zheng","userId":"10224114907197839961"}},"outputId":"390a2469-1452-4bc3-b1ae-3b7cd25a79bd"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%run load_dataset.py\n","%run load_model.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MolG3_5QBRq3","executionInfo":{"status":"ok","timestamp":1670870574925,"user_tz":300,"elapsed":24535,"user":{"displayName":"Shiyang Zheng","userId":"10224114907197839961"}},"outputId":"663c9e6a-702f-48b8-f960-c00969cecc80"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"]}]},{"cell_type":"markdown","metadata":{"id":"30t8wFi9ASO1"},"source":["### Dataset"]},{"cell_type":"markdown","metadata":{"id":"p5YrIxEAASO2"},"source":["download kaggle dataset: https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset/download?datasetVersionNumber=1  \n","download liar dataset: https://www.cs.ucsb.edu/~william/data/liar_dataset.zip"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"PyfQmrriASO3","executionInfo":{"status":"ok","timestamp":1670870682636,"user_tz":300,"elapsed":16893,"user":{"displayName":"Shiyang Zheng","userId":"10224114907197839961"}}},"outputs":[],"source":["import keras\n","from load_dataset import kaggle_dataset\n","from load_dataset import liar_dataset\n","# Select a model\n","from load_model import lstm\n","# lstm(LSTM_units, embedding)\n","from load_model import cnn_lstm\n","# cnn_lstm(cov_filters, cov_kernel, pool_size, LSTM_units, embedding)\n","from load_model import dense\n","# dense(embedding, neural=64)\n","from load_model import dense_dropout\n","# dense_dropout(embedding, dropout=0.1, neural_1=256, neural_2=64)\n","kaggle_path = \"/content/drive/MyDrive/MLCYBER/Data/Fake-News/\"\n","liar_path = \"/content/drive/MyDrive/MLCYBER/Data/LIAR/\"\n","\n","# Pick dataset you want:\n","# If kaggle:\n","# dataset = kaggle_dataset(kaggle_path)\n","# If Liar:\n","dataset = liar_dataset(liar_path)\n","\n","train_sentences = dataset.train_sentences\n","val_sentences = dataset.val_sentences\n","train_labels = dataset.train_labels\n","val_labels = dataset.val_labels"]},{"cell_type":"code","source":["print(val_sentences[30])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WQEZjc9PFLOO","executionInfo":{"status":"ok","timestamp":1670870968840,"user_tz":300,"elapsed":4,"user":{"displayName":"Shiyang Zheng","userId":"10224114907197839961"}},"outputId":"9414f13c-8c35-4c5c-b8d6-03e8203628ac"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Its been since 1888 that a Senate of a different party than the president in the White House confirmed a Supreme Court nominee.\n"]}]},{"cell_type":"code","source":["# for the fake news detection\n","import csv\n","with open(\"/content/drive/MyDrive/MLCYBER/Data/Fake-News/test.csv\", 'wt') as out_file:\n","    tsv_writer = csv.writer(out_file)\n","    for i in range(len(val_sentences)):\n","        tsv_writer.writerow([val_sentences[i], val_labels[i]])"],"metadata":{"id":"pP2YOuxf7bfG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nG_EcH4UASO4"},"source":["### Model"]},{"cell_type":"markdown","metadata":{"id":"JE9kfhibASO4"},"source":["##### Word Enbedding:  \n","pre-trained text embedding model from TensorFlow Hub  \n","more text-embedding download in https://tfhub.dev/s?module-type=text-embedding  \n","NNLM:  \n","plain text -> value [batch_size, 128]  \n","BERT:  \n","plain text -> pooled_output [batch_size, 128]  \n","              sequence_output [batch_size, seq_length, 128]  "]},{"cell_type":"markdown","metadata":{"id":"mn3uhHsSASO5"},"source":["##### Network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nhra_o9FASO6"},"outputs":[],"source":["# Split a small batch of dataset to continue (save time...)\n","i = 2000\n","train_x = train_sentences[:i]\n","val_x = val_sentences[:int(0.2*i)]\n","train_y = train_labels[:i]\n","val_y = val_labels[:int(0.2*i)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oMzkctJfASO6"},"outputs":[],"source":["cov_filters = 64\n","cov_kernel = 5\n","pool_size = 4\n","LSTM_units = 100\n","dropout = 0.2\n","embedding = \"bert\"\n","neural1 = 256 #for dense\n","neural2 = 64 #for dense"]},{"cell_type":"code","source":["training = True\n","#training = False\n","epochs = 5\n","name = 'cnn_lstm'\n","\n","if training:\n","    if name == 'lstm':\n","        model = lstm(LSTM_units = LSTM_units, dropout = dropout, embedding = embedding)\n","    elif name == 'cnn_lstm':\n","        model = cnn_lstm(cov_filters = cov_filters, cov_kernel = cov_kernel, pool_size = pool_size, \n","                         LSTM_units = LSTM_units, dropout = dropout, embedding = embedding)\n","    elif name == 'dense':\n","        model = dense(embedding = embedding, neural = neural2)\n","    elif name == 'dense_dropout':\n","        model = dense_dropout(embedding = embedding, dropout = dropout, neural_1 = neural1, neural_2 = neural2)\n","    else:\n","        print(\"Invalid model name\")\n","    model.summary()\n","    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    model_history = model.fit(train_x, train_y, validation_data=(val_x, val_y),epochs=epochs)\n","    model.save(f\"/content/drive/MyDrive/MLCYBER/Models/model_{name}_{embedding}.h5\")\n","else:\n","    model = keras.models.load_model(f\"/content/drive/MyDrive/MLCYBER/Models/model_{name}_{embedding}.h5\", custom_objects={'KerasLayer': hub.KerasLayer})\n","    print(\"model loaded\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DRqWr38se0ZN","executionInfo":{"status":"ok","timestamp":1670795079221,"user_tz":300,"elapsed":270554,"user":{"displayName":"Shiyang Zheng","userId":"10224114907197839961"}},"outputId":"b38daf6e-1b09-4766-cf2f-1e5ce3f452e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None,)]            0           []                               \n","                                                                                                  \n"," keras_layer_4 (KerasLayer)     {'input_type_ids':   0           ['input_1[0][0]']                \n","                                (None, 128),                                                      \n","                                 'input_word_ids':                                                \n","                                (None, 128),                                                      \n","                                 'input_mask': (Non                                               \n","                                e, 128)}                                                          \n","                                                                                                  \n"," keras_layer_6 (KerasLayer)     (None, 128, 128)     4782465     ['keras_layer_4[0][0]',          \n","                                                                  'keras_layer_4[0][1]',          \n","                                                                  'keras_layer_4[0][2]']          \n","                                                                                                  \n"," dropout (Dropout)              (None, 128, 128)     0           ['keras_layer_6[0][0]']          \n","                                                                                                  \n"," conv1d (Conv1D)                (None, 124, 64)      41024       ['dropout[0][0]']                \n","                                                                                                  \n"," max_pooling1d (MaxPooling1D)   (None, 31, 64)       0           ['conv1d[0][0]']                 \n","                                                                                                  \n"," lstm (LSTM)                    (None, 100)          66000       ['max_pooling1d[0][0]']          \n","                                                                                                  \n"," dense (Dense)                  (None, 1)            101         ['lstm[0][0]']                   \n","                                                                                                  \n","==================================================================================================\n","Total params: 4,889,590\n","Trainable params: 107,125\n","Non-trainable params: 4,782,465\n","__________________________________________________________________________________________________\n","Epoch 1/5\n","63/63 [==============================] - 50s 672ms/step - loss: 0.3770 - accuracy: 0.8210 - val_loss: 0.1681 - val_accuracy: 0.9525\n","Epoch 2/5\n","63/63 [==============================] - 43s 682ms/step - loss: 0.2009 - accuracy: 0.9215 - val_loss: 0.1102 - val_accuracy: 0.9700\n","Epoch 3/5\n","63/63 [==============================] - 44s 696ms/step - loss: 0.1099 - accuracy: 0.9640 - val_loss: 0.0465 - val_accuracy: 0.9825\n","Epoch 4/5\n","63/63 [==============================] - 36s 577ms/step - loss: 0.0535 - accuracy: 0.9840 - val_loss: 0.0469 - val_accuracy: 0.9900\n","Epoch 5/5\n","63/63 [==============================] - 40s 646ms/step - loss: 0.0494 - accuracy: 0.9895 - val_loss: 0.0160 - val_accuracy: 0.9975\n"]}]},{"cell_type":"markdown","metadata":{"id":"1L5kxXm9ASO8"},"source":["### Attack (TBC)"]},{"cell_type":"code","source":["#read attacked datas\n","df_neg_attacked = pd.read_csv(\"/content/drive/MyDrive/MLCYBER/Data/LIAR/test_neg_attacked.tsv\", sep=\"\\t\", header=None)\n","df_neg_unattacked = pd.read_csv(\"/content/drive/MyDrive/MLCYBER/Data/LIAR/test_neg_unattacked.tsv\", sep=\"\\t\", header=None)\n","\n","attacked_sentences = df_neg_attacked[0].to_numpy()\n","unattacked_sentences = df_neg_unattacked[0].to_numpy()\n","attacked_labels = np.array(df_neg_attacked[1])\n","unattacked_labels = np.array(df_neg_unattacked[1])\n","'''\n","df_neg_attacked = pd.read_csv(\"/content/drive/MyDrive/MLCYBER/Data/Fake-News/fake_news_attacked.csv\", header=None)\n","df_neg_unattacked = pd.read_csv(\"/content/drive/MyDrive/MLCYBER/Data/Fake-News/fake_news_unattacked.csv\", header=None)\n","df_neg_attacked.columns = ['statement','label']\n","df_neg_unattacked.columns = ['statement','label']\n","\n","attacked_sentences = df_neg_attacked['statement'].to_numpy()[1:]\n","unattacked_sentences = df_neg_unattacked['statement'].to_numpy()[1:]\n","attacked_labels = np.array(df_neg_attacked['label'][1:], dtype = np.int32)\n","unattacked_labels = np.array(df_neg_unattacked['label'][1:], dtype = np.int32)\n","'''"],"metadata":{"id":"ltdK9dZZDQP4","executionInfo":{"status":"ok","timestamp":1670870989264,"user_tz":300,"elapsed":767,"user":{"displayName":"Shiyang Zheng","userId":"10224114907197839961"}},"colab":{"base_uri":"https://localhost:8080/","height":105},"outputId":"913b68b5-0d18-4955-a2aa-2f035e3884b7"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\ndf_neg_attacked = pd.read_csv(\"/content/drive/MyDrive/MLCYBER/Data/Fake-News/fake_news_attacked.csv\", header=None)\\ndf_neg_unattacked = pd.read_csv(\"/content/drive/MyDrive/MLCYBER/Data/Fake-News/fake_news_unattacked.csv\", header=None)\\ndf_neg_attacked.columns = [\\'statement\\',\\'label\\']\\ndf_neg_unattacked.columns = [\\'statement\\',\\'label\\']\\n\\nattacked_sentences = df_neg_attacked[\\'statement\\'].to_numpy()[1:]\\nunattacked_sentences = df_neg_unattacked[\\'statement\\'].to_numpy()[1:]\\nattacked_labels = np.array(df_neg_attacked[\\'label\\'][1:], dtype = np.int32)\\nunattacked_labels = np.array(df_neg_unattacked[\\'label\\'][1:], dtype = np.int32)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["index = 102\n","print(unattacked_sentences[index])\n","print(attacked_sentences[index])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BrnyTPfFe7_K","executionInfo":{"status":"ok","timestamp":1670871269166,"user_tz":300,"elapsed":587,"user":{"displayName":"Shiyang Zheng","userId":"10224114907197839961"}},"outputId":"be6c086a-8662-4770-cbb9-6441d12cfab8"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["says congressman jon runyan does not want to cut taxes for the middle class, but only for millionaires.\n","says congressman jon runyan wants to cut taxes for the middle class, but only for millionaires.\n"]}]},{"cell_type":"code","source":["model.evaluate(attacked_sentences, attacked_labels)\n","model.evaluate(unattacked_sentences, unattacked_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D5m9rnn2GVv-","executionInfo":{"status":"ok","timestamp":1670795347394,"user_tz":300,"elapsed":259410,"user":{"displayName":"Shiyang Zheng","userId":"10224114907197839961"}},"outputId":"91d105d3-b277-476f-bff6-4f98d2c45699"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["267/267 [==============================] - 115s 423ms/step - loss: 5.1833 - accuracy: 0.0062\n","267/267 [==============================] - 115s 432ms/step - loss: 0.0275 - accuracy: 0.9943\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.027486611157655716, 0.9942582845687866]"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["predict_labels_unt = model(unattacked_sentences)\n","predict_labels_att = model(attacked_sentences)"],"metadata":{"id":"zJjXA_Wn9NpZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels_unt = []\n","labels_att = []\n","for i in range(len(predict_labels_unt)):\n","  if predict_labels_unt[i][0] >= 0.5:\n","    labels_unt.append(1)\n","  else:\n","    labels_unt.append(0)\n","  if predict_labels_att[i][0] >= 0.5:\n","    labels_att.append(1)\n","  else:\n","    labels_att.append(0)\n","labels_unt = np.array(labels_unt)\n","labels_att = np.array(labels_att)"],"metadata":{"id":"8xxmt6AEBuzi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total = 0\n","success = 0\n","for i in range(len(labels_unt)):\n","  if labels_unt[i] == unattacked_labels[i]:\n","    total += 1\n","    if labels_att[i] != attacked_labels[i]:\n","      success += 1\n","    #else:\n","      #print(attacked_sentences[i])\n","      #print(unattacked_sentences[i])\n","print(f\"{success} out of the total {total} correct datas are attacked successfully\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qiE85mKDDSJW","executionInfo":{"status":"ok","timestamp":1670795569555,"user_tz":300,"elapsed":309,"user":{"displayName":"Shiyang Zheng","userId":"10224114907197839961"}},"outputId":"bb3259fb-66cf-4bf5-ea87-b5b3f1081b21"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["8481 out of the total 8485 correct datas are attacked successfully\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uwoNUPwSASO8"},"outputs":[],"source":["import numpy as np\n","import torch\n","\n","from textattack.models.wrappers import ModelWrapper\n","from textattack import AttackArgs\n","from textattack import Attacker\n","from textattack.datasets import Dataset\n","\n","class CustomTensorFlowModelWrapper(ModelWrapper):\n","    def __init__(self, model):\n","        self.model = model\n","\n","    def __call__(self, text_input_list):\n","        text_array = np.array(text_input_list)\n","        preds = self.model(text_array).numpy()\n","        logits = torch.exp(-torch.tensor(preds))\n","        logits = 1 / (1 + logits)\n","        logits = logits.squeeze(dim=-1)\n","        # Since this model only has a single output (between 0 or 1),\n","        # we have to add the second dimension.\n","        final_preds = torch.stack((1-logits, logits), dim=1)\n","        return final_preds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6HnE4m60ASO9","outputId":"fd2a5456-c84e-4a11-af62-8da3e9c5d662"},"outputs":[{"name":"stderr","output_type":"stream","text":["textattack: Unknown if model of class <class 'load_model.lstm'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n"]}],"source":["from textattack.attack_recipes import DeepWordBugGao2018 as attack_recipe\n","\n","i = 100\n","train_dataset = []\n","for example, label in zip(train_sentences[:i], train_labels[:i]):\n","    train_dataset.append((example, int(label)))\n","train_dataset = Dataset(train_dataset)\n","\n","model_wrapper = CustomTensorFlowModelWrapper(model)\n","attack = attack_recipe.build(model_wrapper)\n","\n","attack_args = AttackArgs(\n","    num_examples=i,\n","    checkpoint_interval=5,\n","    disable_stdout=True\n",")\n","\n","attacker = Attacker(attack, train_dataset, attack_args)\n","# attacker.attack_dataset()"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.13 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"8a25a3045e4a92a066b293f5d1fcbf77c7942245a158d0519cc010931d6ca13e"}},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}